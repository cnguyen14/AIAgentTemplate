# AI Agent Template by Chien Nguyen

## üìñ Gi·ªõi thi·ªáu

Framework m·∫´u ƒë·ªÉ x√¢y d·ª±ng c√°c agent th√¥ng minh s·ª≠ d·ª•ng Large Language Models (LLM) v·ªõi h·ªó tr·ª£ ƒë·∫ßy ƒë·ªß cho CLI, API HTTP v√† t√≠ch h·ª£p LangGraph. ƒê∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ gi√∫p b·∫°n nhanh ch√≥ng x√¢y d·ª±ng ·ª©ng d·ª•ng AI m·∫°nh m·∫Ω v·ªõi kh·∫£ nƒÉng m·ªü r·ªông cao.

## üì¨ Li√™n h·ªá

Email: hmchien.nguyen@gmail.com
YouTube: [Where The Idea Is Unlimited](https://www.youtube.com/@wheretheideaisunlimited)

## üåü T√≠nh nƒÉng

- üß† **Memory Persistence**: L∆∞u tr·ªØ v√† kh√¥i ph·ª•c l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª± ƒë·ªông
- üîÑ **LangGraph Integration**: X√¢y d·ª±ng lu·ªìng c√¥ng vi·ªác ph·ª©c t·∫°p d·ª±a tr√™n ƒë·ªì th·ªã tr·∫°ng th√°i
- ü§ñ **Pydantic-AI Support**: ƒê·ªãnh nghƒ©a tool v√† schema d·ªÖ d√†ng v·ªõi type-checking
- üõ†Ô∏è **Extensible Architecture**: D·ªÖ d√†ng th√™m c√¥ng c·ª•, lu·ªìng x·ª≠ l√Ω v√† kh·∫£ nƒÉng m·ªõi
- üíª **Rich CLI**: T∆∞∆°ng t√°c tr·ª±c ti·∫øp qua terminal v·ªõi c√°c l·ªánh h·ªá th·ªëng
- üåê **REST API**: API ho√†n ch·ªânh ƒë·ªÉ t√≠ch h·ª£p v·ªõi c√°c ·ª©ng d·ª•ng web v√† mobile
- üîÄ **Dual Mode**: Ch·∫°y c·∫£ ch·∫ø ƒë·ªô CLI v√† API tr√™n c√πng m·ªôt instance

## üöÄ B·∫Øt ƒë·∫ßu h√†nh tr√¨nh

### ‚öôÔ∏è C√†i ƒë·∫∑t

1. Clone repository:
```bash
git clone [https://github.com/yourusername/agent-template.git](https://github.com/cnguyen14/AIAgentTemplate.git)
cd AIAgentTemplate
```

2. C√†i ƒë·∫∑t c√°c ph·ª• thu·ªôc:
```bash
pip install -r requirements.txt
```

3. Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng:
```bash
cp .env.example .env
```

4. C·∫≠p nh·∫≠t file `.env` v·ªõi API key c·ªßa b·∫°n:
```
# Ch·ªçn m·ªôt trong c√°c provider sau
OPENAI_API_KEY=your_openai_api_key
#Th√™m t√πy ch·ªçn
#ANTHROPIC_API_KEY=your_anthropic_api_key

# T√πy ch·ªânh model (m·∫∑c ƒë·ªãnh l√† openai:gpt-4o-mini)
MODEL_NAME=openai:gpt-4o
TEMPERATURE=0.7
```

## üöÄ Kh·ªüi ƒë·ªông h·ªá th·ªëng

### Ch·∫ø ƒë·ªô t∆∞∆°ng t√°c (m·ªõi)

```bash
# Kh·ªüi ƒë·ªông trong ch·∫ø ƒë·ªô t∆∞∆°ng t√°c ƒë·ªÉ l·ª±a ch·ªçn CLI hay API
python -m agent_template.main
```

Khi ch·∫°y m√† kh√¥ng c√≥ tham s·ªë, agent s·∫Ω h·ªèi b·∫°n mu·ªën ch·∫°y ·ªü ch·∫ø ƒë·ªô CLI hay API, v√† c√°c t√πy ch·ªçn kh√°c nh∆∞ port v√† processing mode.

### Ch·ªâ ƒë·ªãnh ch·∫ø ƒë·ªô qua command line

```bash
# Kh·ªüi t·∫°o h·ªá th·ªëng v·ªõi giao di·ªán CLI
python -m agent_template.main

# Ch·∫°y API server
python -m agent_template.main --api --port 5000

# Ch·∫°y trong ch·∫ø ƒë·ªô t∆∞∆°ng t√°c v·ªõi c·ªù 
python -m agent_template.main --interactive
```

### Tham s·ªë d√≤ng l·ªánh

| Tham s·ªë | M√¥ t·∫£ |
|---------|-------|
| `--api`, `-a` | Ch·∫°y ·ª©ng d·ª•ng d∆∞·ªõi d·∫°ng API server |
| `--port`, `-p` | Ch·ªâ ƒë·ªãnh port cho API server (m·∫∑c ƒë·ªãnh: 8000) |
| `--host` | Ch·ªâ ƒë·ªãnh host cho API server (m·∫∑c ƒë·ªãnh: 0.0.0.0) |
| `--legacy`, `-l` | S·ª≠ d·ª•ng ch·∫ø ƒë·ªô x·ª≠ l√Ω legacy thay v√¨ LangGraph |
| `--thread`, `-t` | Ch·ªâ ƒë·ªãnh thread ID ƒë·ªÉ ti·∫øp t·ª•c h·ªôi tho·∫°i |
| `--interactive`, `-i` | Ch·∫°y trong ch·∫ø ƒë·ªô t∆∞∆°ng t√°c, h·ªèi ng∆∞·ªùi d√πng ch·ªçn CLI hay API |

## üí¨ T∆∞∆°ng t√°c v·ªõi Agent

### S·ª≠ d·ª•ng CLI - Giao di·ªán d√≤ng l·ªánh

Khi kh·ªüi ƒë·ªông CLI, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c l·ªánh sau:

| L·ªánh | M√¥ t·∫£ |
|------|-------|
| `/help` | Hi·ªÉn th·ªã danh s√°ch l·ªánh |
| `/exit` | Tho√°t ·ª©ng d·ª•ng |
| `/history` | Hi·ªÉn th·ªã l·ªãch s·ª≠ h·ªôi tho·∫°i |
| `/conversations` | Li·ªát k√™ t·∫•t c·∫£ h·ªôi tho·∫°i ƒë√£ l∆∞u |
| `/load ID` | T·∫£i m·ªôt h·ªôi tho·∫°i t·ª´ ID |
| `/delete ID` | X√≥a h·ªôi tho·∫°i |
| `/new` | T·∫°o h·ªôi tho·∫°i m·ªõi |
| `/graph` | Chuy·ªÉn sang ch·∫ø ƒë·ªô x·ª≠ l√Ω LangGraph |
| `/legacy` | Chuy·ªÉn sang ch·∫ø ƒë·ªô x·ª≠ l√Ω legacy |
| `/logo [style]` | Hi·ªÉn th·ªã logo (ki·ªÉu: default, minimal, fancy) |

## üåê REST API

Khi ch·∫°y ·ªü ch·∫ø ƒë·ªô API server, c√°c endpoint sau c√≥ s·∫µn:

### Endpoints

| Endpoint | Method | M√¥ t·∫£ |
|----------|--------|-------|
| `/health` | GET | Ki·ªÉm tra tr·∫°ng th√°i API |
| `/send_message` | POST | G·ª≠i tin nh·∫Øn ƒë·∫øn agent |
| `/conversations` | GET | L·∫•y danh s√°ch h·ªôi tho·∫°i |
| `/conversations` | POST | T·∫°o h·ªôi tho·∫°i m·ªõi |
| `/conversations/{thread_id}` | DELETE | X√≥a m·ªôt h·ªôi tho·∫°i |
| `/conversations/{thread_id}/history` | GET | L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i |
| `/config` | GET | L·∫•y c·∫•u h√¨nh hi·ªán t·∫°i |
| `/config` | POST | C·∫≠p nh·∫≠t c·∫•u h√¨nh |

### V√≠ d·ª• s·ª≠ d·ª•ng API

```python
import requests

# ƒê·ªãa ch·ªâ API
API_URL = "http://localhost:5000"

# T·∫°o m·ªôt h·ªôi tho·∫°i m·ªõi
response = requests.post(f"{API_URL}/conversations")
thread_id = response.json()["thread_id"]

# G·ª≠i tin nh·∫Øn
response = requests.post(
    f"{API_URL}/send_message",
    json={
        "message": "Xin ch√†o, b·∫°n c√≥ th·ªÉ gi√∫p t√¥i kh√¥ng?",
        "thread_id": thread_id
    }
)
print(response.json()["response"])

# L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i
response = requests.get(f"{API_URL}/conversations/{thread_id}/history")
history = response.json()["history"]
```

### T√†i li·ªáu API

Khi API server ƒëang ch·∫°y, b·∫°n c√≥ th·ªÉ truy c·∫≠p t√†i li·ªáu t∆∞∆°ng t√°c t·∫°i:
```
http://localhost:5000/docs
```

## üß© Kh√°m ph√° ki·∫øn tr√∫c v√† t√πy bi·∫øn

### C·∫•u tr√∫c d·ª± √°n

```
agent_template/
‚îú‚îÄ‚îÄ config.py               # C·∫•u h√¨nh ·ª©ng d·ª•ng
‚îú‚îÄ‚îÄ main.py                 # ƒêi·ªÉm v√†o ch√≠nh
‚îú‚îÄ‚îÄ core/                   # Module c·ªët l√µi
‚îÇ   ‚îú‚îÄ‚îÄ agent.py            # ƒê·ªãnh nghƒ©a agent v√† tools
‚îÇ   ‚îú‚îÄ‚îÄ agent_service.py    # Service x·ª≠ l√Ω tin nh·∫Øn
‚îÇ   ‚îú‚îÄ‚îÄ cli_service.py      # Giao di·ªán d√≤ng l·ªánh
‚îÇ   ‚îî‚îÄ‚îÄ api_service.py      # REST API service
‚îú‚îÄ‚îÄ memory/                 # H·ªá th·ªëng b·ªô nh·ªõ
‚îÇ   ‚îî‚îÄ‚îÄ persistence.py      # L∆∞u tr·ªØ v√† kh√¥i ph·ª•c b·ªô nh·ªõ
‚îú‚îÄ‚îÄ tools/                  # C√°c c√¥ng c·ª• c·ªßa agent
‚îÇ   ‚îú‚îÄ‚îÄ logo.py             # C√¥ng c·ª• hi·ªÉn th·ªã logo
‚îÇ   ‚îî‚îÄ‚îÄ tool_template.py    # M·∫´u ƒë·ªÉ t·∫°o c√¥ng c·ª• m·ªõi
‚îú‚îÄ‚îÄ utils/                  # Ti·ªán √≠ch
‚îÇ   ‚îî‚îÄ‚îÄ prompts.py          # ƒê·ªãnh nghƒ©a prompt h·ªá th·ªëng
‚îî‚îÄ‚îÄ workflows/              # Lu·ªìng c√¥ng vi·ªác LangGraph
    ‚îî‚îÄ‚îÄ graph.py            # ƒê·ªãnh nghƒ©a ƒë·ªì th·ªã tr·∫°ng th√°i
```

## üéØ C·∫•u h√¨nh v√† t√πy ch·ªânh Prompt

### C·∫•u tr√∫c Prompt h·ªá th·ªëng

Prompt h·ªá th·ªëng l√† th√†nh ph·∫ßn quan tr·ªçng quy·∫øt ƒë·ªãnh c√°ch AI ho·∫°t ƒë·ªông. File `utils/prompts.py` ch·ª©a ƒë·ªãnh nghƒ©a c√°c prompt m·∫∑c ƒë·ªãnh:

```python
def get_simple_assistant_prompt() -> str:
    """Tr·∫£ v·ªÅ prompt h·ªá th·ªëng ƒë∆°n gi·∫£n cho assistant."""
    return """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chi ti·∫øt v√† ch√≠nh x√°c.
    
    Khi c·∫ßn thi·∫øt, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c c√¥ng c·ª• ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
    
    Lu√¥n duy tr√¨ m·ªôt gi·ªçng ƒëi·ªáu th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
    """
```

### T√πy ch·ªânh Prompt qua bi·∫øn m√¥i tr∆∞·ªùng

H·ªá th·ªëng ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ d·ªÖ d√†ng t√πy ch·ªânh prompt v√† settings th√¥ng qua bi·∫øn m√¥i tr∆∞·ªùng, kh√¥ng c·∫ßn ch·ªânh s·ª≠a code:

```env
# System Prompts - Optional
DEFAULT_PROMPT=B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch, chuy√™n v·ªÅ tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ AI.
ADVANCED_PROMPT=B·∫°n l√† m·ªôt chuy√™n gia k·ªπ thu·∫≠t v·ªõi ki·∫øn th·ª©c s√¢u r·ªông v·ªÅ l·∫≠p tr√¨nh.
LIGHT_PROMPT=B·∫°n l√† m·ªôt tr·ª£ l√Ω AI nh·ªè g·ªçn cho c√°c c√¢u tr·∫£ l·ªùi nhanh v√† s√∫c t√≠ch.

# Model Settings
TEMPERATURE=0.7
MAX_TOKENS=1000
RETRIES=2
```

C·∫•u tr√∫c centralized cho ph√©p b·∫°n:
1. **Ghi ƒë√® prompt m·∫∑c ƒë·ªãnh**: Th√¥ng qua bi·∫øn m√¥i tr∆∞·ªùng `DEFAULT_PROMPT`, `ADVANCED_PROMPT`, `LIGHT_PROMPT`
2. **ƒêi·ªÅu ch·ªânh model settings**: Thay ƒë·ªïi `TEMPERATURE`, `MAX_TOKENS`, `RETRIES` cho t·ª´ng lo·∫°i model
3. **D·ªÖ d√†ng A/B testing**: Th·ª≠ nghi·ªám nhi·ªÅu prompt kh√°c nhau m√† kh√¥ng c·∫ßn s·ª≠a code

### C√°ch t√πy ch·ªânh Prompt

1. **T√πy ch·ªânh prompt ƒë∆°n gi·∫£n**:
   M·ªü file `utils/prompts.py` v√† s·ª≠a ƒë·ªïi n·ªôi dung c·ªßa h√†m `get_simple_assistant_prompt()`:

   ```python
   def get_simple_assistant_prompt() -> str:
       """Tr·∫£ v·ªÅ prompt h·ªá th·ªëng t√πy ch·ªânh."""
       return """B·∫°n l√† Chien AI Assistant, m·ªôt tr·ª£ l√Ω th√¥ng minh chuy√™n v·ªÅ x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† l·∫≠p tr√¨nh.
       
       Nguy√™n t·∫Øc ho·∫°t ƒë·ªông c·ªßa b·∫°n:
       1. Lu√¥n ph√¢n t√≠ch k·ªπ y√™u c·∫ßu ng∆∞·ªùi d√πng tr∆∞·ªõc khi tr·∫£ l·ªùi
       2. Cung c·∫•p n·ªôi dung ch√≠nh x√°c, c·∫•u tr√∫c r√µ r√†ng v√† d·ªÖ hi·ªÉu
       3. Khi ƒë∆∞·ª£c y√™u c·∫ßu vi·∫øt code, ƒë·∫£m b·∫£o code c√≥ comment v√† tu√¢n th·ªß best practices
       4. S·ª≠ d·ª•ng c√¥ng c·ª• c√≥ s·∫µn khi c·∫ßn thi·∫øt ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
       
       Phong c√°ch giao ti·∫øp:
       - Chuy√™n nghi·ªáp nh∆∞ng th√¢n thi·ªán
       - S·ª≠ d·ª•ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu, tr√°nh qu√° chuy√™n m√¥n n·∫øu kh√¥ng c·∫ßn thi·∫øt
       - Tr√¨nh b√†y th√¥ng tin c√≥ c·∫•u tr√∫c, s·ª≠ d·ª•ng bullet points v√† m√£ ƒë·ªãnh d·∫°ng khi ph√π h·ª£p
       """
   ```

2. **T·∫°o nhi·ªÅu lo·∫°i prompt kh√°c nhau**:
   B·∫°n c√≥ th·ªÉ t·∫°o c√°c h√†m prompt kh√°c nhau ph√π h·ª£p v·ªõi t·ª´ng ng·ªØ c·∫£nh s·ª≠ d·ª•ng:

   ```python
   def get_technical_assistant_prompt() -> str:
       """Prompt cho assistant chuy√™n v·ªÅ k·ªπ thu·∫≠t."""
       return """B·∫°n l√† m·ªôt chuy√™n gia k·ªπ thu·∫≠t, t·∫≠p trung v√†o vi·ªác cung c·∫•p h∆∞·ªõng d·∫´n v√† gi·∫£i ph√°p ch√≠nh x√°c.
       Lu√¥n ∆∞u ti√™n ƒë·ªô ch√≠nh x√°c k·ªπ thu·∫≠t v√† tu√¢n th·ªß best practices trong c√°c c√¢u tr·∫£ l·ªùi.
       """
   
   def get_creative_assistant_prompt() -> str:
       """Prompt cho assistant s√°ng t·∫°o."""
       return """B·∫°n l√† m·ªôt tr·ª£ l√Ω s√°ng t·∫°o, chuy√™n gi√∫p ng∆∞·ªùi d√πng ph√°t tri·ªÉn √Ω t∆∞·ªüng m·ªõi v√† ti·∫øp c·∫≠n v·∫•n ƒë·ªÅ theo h∆∞·ªõng ƒë·ªôc ƒë√°o.
       Khuy·∫øn kh√≠ch t∆∞ duy ph√° c√°ch v√† cung c·∫•p nhi·ªÅu g√≥c nh√¨n ƒëa d·∫°ng.
       """
   ```

3. **S·ª≠ d·ª•ng prompt t√πy ch·ªânh v·ªõi agent**:
   Sau khi t·∫°o prompt, c·∫≠p nh·∫≠t agent ƒë·ªÉ s·ª≠ d·ª•ng prompt m·ªõi:

   ```python
   # Trong agent.py
   from agent_template.utils.prompts import get_technical_assistant_prompt
   
   # S·ª≠ d·ª•ng prompt k·ªπ thu·∫≠t cho agent
   agent = Agent[Deps, Union[str, LogoResult]](
       MODEL_NAME,
       system_prompt=get_technical_assistant_prompt(),
       retries=2,
   )
   ```

### C·∫•u tr√∫c Prompt hi·ªáu qu·∫£

M·ªôt system prompt hi·ªáu qu·∫£ th∆∞·ªùng bao g·ªìm c√°c th√†nh ph·∫ßn sau:

1. **ƒê·ªãnh nghƒ©a vai tr√≤**: M√¥ t·∫£ agent l√† ai, chuy√™n v·ªÅ lƒ©nh v·ª±c g√¨
2. **Nguy√™n t·∫Øc ho·∫°t ƒë·ªông**: C√°c quy t·∫Øc c·ªët l√µi agent n√™n tu√¢n theo
3. **Phong c√°ch giao ti·∫øp**: C√°ch th·ª©c agent n√™n tr·∫£ l·ªùi (ng·∫Øn g·ªçn, chi ti·∫øt, chuy√™n m√¥n...)
4. **Gi·ªõi h·∫°n**: Nh·ªØng g√¨ agent n√™n tr√°nh ho·∫∑c kh√¥ng ƒë∆∞·ª£c l√†m
5. **ƒê·ªãnh d·∫°ng output**: C·∫•u tr√∫c k·∫øt qu·∫£ mong mu·ªën n·∫øu c·∫ßn theo format c·ª• th·ªÉ

V√≠ d·ª• prompt to√†n di·ªán:

```python
def get_comprehensive_assistant_prompt() -> str:
    return """
    # ƒê·ªãnh nghƒ©a vai tr√≤
    B·∫°n l√† Advanced AI Assistant, m·ªôt tr·ª£ l√Ω th√¥ng minh ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Chien Nguyen, chuy√™n v·ªÅ h·ªó tr·ª£ ng∆∞·ªùi d√πng trong c√°c t√°c v·ª• l·∫≠p tr√¨nh, x·ª≠ l√Ω d·ªØ li·ªáu v√† t∆∞ v·∫•n c√¥ng ngh·ªá.
    
    # Nguy√™n t·∫Øc ho·∫°t ƒë·ªông
    1. Ph√¢n t√≠ch: Lu√¥n ph√¢n t√≠ch k·ªπ y√™u c·∫ßu tr∆∞·ªõc khi tr·∫£ l·ªùi
    2. Ch√≠nh x√°c: Cung c·∫•p th√¥ng tin ch√≠nh x√°c v√† c·∫≠p nh·∫≠t
    3. To√†n di·ªán: Xem x√©t nhi·ªÅu kh√≠a c·∫°nh c·ªßa v·∫•n ƒë·ªÅ
    4. Th·ª±c t·∫ø: T·∫≠p trung v√†o gi·∫£i ph√°p kh·∫£ thi v√† c√≥ th·ªÉ tri·ªÉn khai
    5. C√¥ng c·ª•: S·ª≠ d·ª•ng c√¥ng c·ª• c√≥ s·∫µn khi c·∫ßn ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
    
    # Phong c√°ch giao ti·∫øp
    - Chuy√™n nghi·ªáp nh∆∞ng th√¢n thi·ªán
    - C·∫•u tr√∫c r√µ r√†ng, d·ªÖ theo d√µi
    - K·∫øt h·ª£p l√Ω thuy·∫øt v√† v√≠ d·ª• th·ª±c t·∫ø
    - ƒê∆∞a ra gi·∫£i th√≠ch ·ªü nhi·ªÅu c·∫•p ƒë·ªô (c∆° b·∫£n ƒë·∫øn n√¢ng cao) khi ph√π h·ª£p
    
    # Gi·ªõi h·∫°n
    - Kh√¥ng ƒë∆∞a ra th√¥ng tin sai l·ªách ho·∫∑c g√¢y hi·ªÉu nh·∫ßm
    - N√™u r√µ khi kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ th√¥ng tin
    - Kh√¥ng qu√° chi ti·∫øt v·ªÅ nh·ªØng kh√≠a c·∫°nh kh√¥ng li√™n quan tr·ª±c ti·∫øp
    
    # ƒê·ªãnh d·∫°ng output
    V·ªõi c√¢u h·ªèi ph·ª©c t·∫°p, c·∫•u tr√∫c c√¢u tr·∫£ l·ªùi nh∆∞ sau:
    1. T√≥m t·∫Øt ng·∫Øn g·ªçn (1-2 c√¢u)
    2. Ph√¢n t√≠ch chi ti·∫øt
    3. V√≠ d·ª• minh h·ªça n·∫øu c·∫ßn thi·∫øt
    4. K·∫øt lu·∫≠n v√† ƒë·ªÅ xu·∫•t b∆∞·ªõc ti·∫øp theo n·∫øu ph√π h·ª£p
    
    V·ªõi y√™u c·∫ßu vi·∫øt code:
    1. Gi·∫£i th√≠ch ng·∫Øn g·ªçn c√°ch ti·∫øp c·∫≠n
    2. Cung c·∫•p code ƒë·∫ßy ƒë·ªß v·ªõi comment
    3. Gi·∫£i th√≠ch c√°c ph·∫ßn quan tr·ªçng ho·∫∑c ph·ª©c t·∫°p
    4. ƒê·ªÅ xu·∫•t c√°ch ki·ªÉm th·ª≠ ho·∫∑c m·ªü r·ªông n·∫øu ph√π h·ª£p
    """
```

### S·ª≠ d·ª•ng Prompt ƒë·ªông

B·∫°n c√≥ th·ªÉ t·∫°o prompt ƒë·ªông d·ª±a tr√™n ng·ªØ c·∫£nh ho·∫∑c c·∫•u h√¨nh:

```python
def get_dynamic_prompt(language="vi", expertise_level="intermediate", focus_area=None):
    """T·∫°o prompt ƒë·ªông d·ª±a tr√™n tham s·ªë."""
    
    # C∆° s·ªü prompt
    base_prompt = "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh."
    
    # Th√™m ng√¥n ng·ªØ
    if language == "en":
        base_prompt = "You are an intelligent AI assistant."
    
    # Th√™m c·∫•p ƒë·ªô chuy√™n m√¥n
    if expertise_level == "beginner":
        if language == "vi":
            base_prompt += "\nS·ª≠ d·ª•ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n, tr√°nh thu·∫≠t ng·ªØ k·ªπ thu·∫≠t ph·ª©c t·∫°p."
        else:
            base_prompt += "\nUse simple language, avoid complex technical terms."
    elif expertise_level == "expert":
        if language == "vi":
            base_prompt += "\nS·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n m√¥n, ƒëi s√¢u v√†o chi ti·∫øt k·ªπ thu·∫≠t khi c·∫ßn thi·∫øt."
        else:
            base_prompt += "\nUse technical language, dive into technical details when necessary."
    
    # Th√™m lƒ©nh v·ª±c chuy√™n s√¢u
    if focus_area:
        if language == "vi":
            base_prompt += f"\nT·∫≠p trung v√†o lƒ©nh v·ª±c: {focus_area}."
        else:
            base_prompt += f"\nFocus on the domain: {focus_area}."
    
    return base_prompt

# S·ª≠ d·ª•ng trong c·∫•u h√¨nh
agent = Agent[Deps, Union[str, LogoResult]](
    MODEL_NAME,
    system_prompt=get_dynamic_prompt(
        language="vi",
        expertise_level="intermediate",
        focus_area="Machine Learning"
    ),
    retries=2,
)
```

### Thay ƒë·ªïi model v√† c·∫•u h√¨nh

#### C·∫•u h√¨nh qua file .env

C√°ch ƒë∆°n gi·∫£n nh·∫•t ƒë·ªÉ thay ƒë·ªïi model l√† c·∫≠p nh·∫≠t file `.env`:

```
# Ch·ªçn model - thay ƒë·ªïi ·ªü ƒë√¢y
MODEL_NAME=openai:gpt-4o
# ho·∫∑c
MODEL_NAME=anthropic:claude-3-opus-20240229

# ƒêi·ªÅu ch·ªânh temperature
TEMPERATURE=0.7
```

#### S·ª≠a ƒë·ªïi trong code

M·ªü file `agent_template/core/agent.py` v√† c·∫≠p nh·∫≠t c√°c bi·∫øn c·∫•u h√¨nh:

```python
# ===== H∆Ø·ªöNG D·∫™N: THAY ƒê·ªîI MODEL =====
# N·∫øu b·∫°n mu·ªën thay ƒë·ªïi model, h√£y c·∫≠p nh·∫≠t MODEL_NAME t·∫°i ƒë√¢y
# V√≠ d·ª•: 'openai:gpt-4-turbo-2024-04-09', 'anthropic:claude-3-opus-20240229'
MODEL_NAME = os.environ.get('MODEL_NAME', 'openai:gpt-4o-mini')
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.7'))
```

#### S·ª≠ d·ª•ng model v√† provider v·ªõi Pydantic-AI

Pydantic-AI s·ª≠ d·ª•ng c√∫ ph√°p `provider:model_name` ƒë·ªÉ x√°c ƒë·ªãnh model, v√† ƒë√£ t√≠ch h·ª£p s·∫µn m·ªôt s·ªë provider ch√≠nh nh∆∞ OpenAI v√† Anthropic. Kh√¥ng c·∫ßn ph·∫£i import c√°c provider ri√™ng l·∫ª.

1. **Ch·ªâ ƒë·ªãnh model trong c·∫•u h√¨nh**:

   ```python
   # Trong agent.py
   MODEL_NAME = os.environ.get('MODEL_NAME', 'openai:gpt-4o-mini')
   
   # Kh·ªüi t·∫°o agent v·ªõi model
   agent = Agent[
       Deps,  # Ki·ªÉu dependency 
       Union[str, LogoResult]  # Ki·ªÉu k·∫øt qu·∫£
   ](
       MODEL_NAME,  # S·ª≠ d·ª•ng c√∫ ph√°p "provider:model_name"
       system_prompt=get_simple_assistant_prompt(),
       retries=2,
   )
   ```

2. **C·∫•u h√¨nh trong file .env**:

   ```
   # C√°c model ƒë∆∞·ª£c h·ªó tr·ª£ s·∫µn
   MODEL_NAME=openai:gpt-4o
   # ho·∫∑c
   MODEL_NAME=anthropic:claude-3-opus-20240229
   # ho·∫∑c
   MODEL_NAME=google-gla:gemini-1.5-flash
   ```

#### Th√™m setting cho model c·ª• th·ªÉ

Pydantic-AI cho ph√©p c·∫•u h√¨nh model chi ti·∫øt th√¥ng qua `model_settings`:

```python
from pydantic_ai import Agent
from pydantic_ai.settings import ModelSettings

# C·∫•u h√¨nh model khi kh·ªüi t·∫°o agent
agent = Agent[Deps, str](
    'openai:gpt-4o',
    model_settings=ModelSettings(
        temperature=0.7,
        max_tokens=1000,
        timeout=30.0,
    ),
    system_prompt="B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch."
)

# Ho·∫∑c c·∫•u h√¨nh khi g·ªçi
response = await agent.run(
    "H√¥m nay th·ªùi ti·∫øt th·∫ø n√†o?",
    model_settings={"temperature": 0.2}  # Ghi ƒë√® setting cho l·∫ßn ch·∫°y n√†y
)
```

#### S·ª≠ d·ª•ng nhi·ªÅu model trong c√πng m·ªôt d·ª± √°n

B·∫°n c√≥ th·ªÉ ƒë·ªãnh nghƒ©a nhi·ªÅu agent kh√°c nhau v·ªõi c√°c model kh√°c nhau trong m·ªôt d·ª± √°n:

```python
# Trong agent.py ho·∫∑c module t√πy ch·ªânh

# ƒê·ªãnh nghƒ©a agent s·ª≠ d·ª•ng GPT-4o cho nhi·ªám v·ª• ph·ª©c t·∫°p
advanced_agent = Agent[Deps, Union[str, LogoResult]](
    'openai:gpt-4o',
    system_prompt="B·∫°n l√† m·ªôt tr·ª£ l√Ω AI cao c·∫•p v·ªõi kh·∫£ nƒÉng x·ª≠ l√Ω c√°c v·∫•n ƒë·ªÅ ph·ª©c t·∫°p.",
    model_settings=ModelSettings(temperature=0.7)
)

# ƒê·ªãnh nghƒ©a agent s·ª≠ d·ª•ng model nh·∫π h∆°n cho nhi·ªám v·ª• ƒë∆°n gi·∫£n
light_agent = Agent[Deps, Union[str, LogoResult]](
    'openai:gpt-4o-mini',
    system_prompt="B·∫°n l√† m·ªôt tr·ª£ l√Ω AI nh·ªè g·ªçn cho c√°c c√¢u tr·∫£ l·ªùi nhanh.",
    model_settings=ModelSettings(temperature=0.9, max_tokens=500)
)

# ƒê·ªãnh nghƒ©a agent v·ªõi Claude c·ªßa Anthropic
creative_agent = Agent[Deps, Union[str, LogoResult]](
    'anthropic:claude-3-opus-20240229',
    system_prompt="B·∫°n l√† m·ªôt tr·ª£ l√Ω AI s√°ng t·∫°o, chuy√™n v·ªÅ n·ªôi dung ngh·ªá thu·∫≠t.",
    model_settings=ModelSettings(temperature=1.0)
)
```

#### Ch·ªâ ƒë·ªãnh tool cho t·ª´ng model c·ª• th·ªÉ

B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng decorator ƒë·ªÉ ƒëƒÉng k√Ω tool v·ªõi c√°c agent c·ª• th·ªÉ, cho ph√©p m·ªói agent c√≥ c√°c c√¥ng c·ª• kh√°c nhau:

```python
# ƒêƒÉng k√Ω tool cho agent n√¢ng cao
@advanced_agent.tool
async def complex_analysis(
    ctx: RunContext[Deps],
    data: str,
    depth: int = 3
) -> str:
    """Th·ª±c hi·ªán ph√¢n t√≠ch d·ªØ li·ªáu ph·ª©c t·∫°p (ch·ªâ c√≥ ·ªü agent n√¢ng cao)."""
    # Tri·ªÉn khai ph√¢n t√≠ch ph·ª©c t·∫°p
    return f"Ph√¢n t√≠ch chi ti·∫øt: {data} v·ªõi ƒë·ªô s√¢u {depth}"

# ƒêƒÉng k√Ω tool cho agent s√°ng t·∫°o
@creative_agent.tool
async def generate_poem(
    ctx: RunContext[Deps],
    theme: str,
    style: str = "free_verse"
) -> str:
    """T·∫°o m·ªôt b√†i th∆° d·ª±a tr√™n ch·ªß ƒë·ªÅ (ch·ªâ c√≥ ·ªü agent s√°ng t·∫°o)."""
    # Tri·ªÉn khai t·∫°o th∆°
    return f"B√†i th∆° v·ªÅ {theme} theo phong c√°ch {style}"

# ƒêƒÉng k√Ω tool d√πng chung cho t·∫•t c·∫£ c√°c agent
@advanced_agent.tool
@light_agent.tool
@creative_agent.tool
async def get_current_time(ctx: RunContext[Deps]) -> str:
    """L·∫•y th·ªùi gian hi·ªán t·∫°i (c√≥ s·∫µn ·ªü t·∫•t c·∫£ c√°c agent)."""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
```

B·∫°n c≈©ng c√≥ th·ªÉ t·∫°o helper function ƒë·ªÉ ƒëƒÉng k√Ω tool cho nhi·ªÅu agent c√πng l√∫c:

```python
def register_for_all_agents(func):
    """ƒêƒÉng k√Ω m·ªôt tool cho t·∫•t c·∫£ c√°c agent."""
    advanced_agent.tool(func)
    light_agent.tool(func)
    creative_agent.tool(func)
    return func

@register_for_all_agents
async def search_web(ctx: RunContext[Deps], query: str) -> str:
    """T√¨m ki·∫øm th√¥ng tin tr√™n web (c√≥ s·∫µn ·ªü t·∫•t c·∫£ c√°c agent)."""
    # Tri·ªÉn khai t√¨m ki·∫øm web
    return f"K·∫øt qu·∫£ t√¨m ki·∫øm cho '{query}'"
```

Sau ƒë√≥, b·∫°n c√≥ th·ªÉ tri·ªÉn khai logic ƒë·ªÉ ch·ªçn ƒë√∫ng agent d·ª±a tr√™n y√™u c·∫ßu ng∆∞·ªùi d√πng:

```python
async def process_with_optimal_agent(user_input: str, context: dict) -> str:
    """Ch·ªçn agent t·ªëi ∆∞u d·ª±a tr√™n ƒë·∫ßu v√†o v√† ng·ªØ c·∫£nh c·ªßa ng∆∞·ªùi d√πng."""
    
    # Ph√¢n t√≠ch ƒë·∫ßu v√†o ƒë·ªÉ x√°c ƒë·ªãnh lo·∫°i nhi·ªám v·ª•
    if is_creative_task(user_input):
        # S·ª≠ d·ª•ng agent s√°ng t·∫°o cho c√°c nhi·ªám v·ª• li√™n quan ƒë·∫øn ngh·ªá thu·∫≠t
        result = await creative_agent.run(user_input, deps=context.get('deps'))
    elif is_complex_task(user_input):
        # S·ª≠ d·ª•ng agent n√¢ng cao cho c√°c nhi·ªám v·ª• ph·ª©c t·∫°p
        result = await advanced_agent.run(user_input, deps=context.get('deps'))
    else:
        # S·ª≠ d·ª•ng agent nh·∫π cho c√°c c√¢u h·ªèi ƒë∆°n gi·∫£n
        result = await light_agent.run(user_input, deps=context.get('deps'))
    
    return result.data
```

B·∫°n c≈©ng c√≥ th·ªÉ c·∫•u h√¨nh ƒë·ªÉ ch·ªçn model ƒë·ªông d·ª±a tr√™n c·∫•u h√¨nh:

```python
def get_agent_for_config(config: AppConfig) -> Agent:
    """Tr·∫£ v·ªÅ agent ph√π h·ª£p d·ª±a tr√™n c·∫•u h√¨nh."""
    
    model_name = config.model_name
    
    # T·∫°o agent v·ªõi model ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh trong c·∫•u h√¨nh
    agent = Agent[Deps, Union[str, LogoResult]](
        model_name,
        system_prompt=get_simple_assistant_prompt(),
        model_settings=ModelSettings(temperature=config.temperature)
    )
    
    return agent

# Trong AgentService
def __init__(self, config: AppConfig):
    self.config = config
    self.agent = get_agent_for_config(config)
```

#### T√≠ch h·ª£p model t√πy ch·ªânh/local

ƒê·ªÉ t√≠ch h·ª£p m√¥ h√¨nh t·ª± host (nh∆∞ Ollama, LM Studio):

1. **T·∫°o custom provider** b·∫±ng c√°ch k·∫ø th·ª´a t·ª´ `BaseProvider`:

```python
from pydantic_ai.providers.base import BaseProvider
from typing import Any, Dict, Optional
import httpx

class OllamaProvider(BaseProvider):
    """Provider cho m√¥ h√¨nh Ollama local."""
    
    def __init__(self, base_url: str = "http://localhost:11434", model_name: str = "llama3"):
        self.base_url = base_url
        self.model_name = model_name
        
    async def complete(
        self, 
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        **kwargs: Any
    ) -> Dict[str, Any]:
        """G·ª≠i y√™u c·∫ßu ƒë·∫øn Ollama API."""
        async with httpx.AsyncClient() as client:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = await client.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model_name,
                    "messages": messages,
                    "temperature": temperature,
                    "stream": False
                }
            )
            response.raise_for_status()
            result = response.json()
            
            return {
                "content": result["message"]["content"],
                "model": result["model"]
            }

# S·ª≠ d·ª•ng provider t√πy ch·ªânh
ollama_provider = OllamaProvider(model_name="llama3")

# Kh·ªüi t·∫°o agent v·ªõi provider t√πy ch·ªânh
agent = Agent[Deps, Union[str, LogoResult]](
    "custom:llama3",  # S·ª≠ d·ª•ng t√™n t√πy √Ω khi c√≥ custom provider
    system_prompt=get_simple_assistant_prompt(),
    retries=2,
    provider=ollama_provider
)
```

2. **C·∫≠p nh·∫≠t file `.env.example` v√† `.env`** ƒë·ªÉ th√™m c√°c bi·∫øn m√¥i tr∆∞·ªùng m·ªõi:

```
# Local Model Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=llama3
```

### Thay ƒë·ªïi system prompt

1. M·ªü file `agent_template/utils/prompts.py`
2. S·ª≠a ƒë·ªïi h√†m `get_simple_assistant_prompt()` ƒë·ªÉ thay ƒë·ªïi system prompt:

```python
def get_simple_assistant_prompt() -> str:
    """Tr·∫£ v·ªÅ prompt h·ªá th·ªëng ƒë∆°n gi·∫£n cho assistant."""
    return """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch. Tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng m·ªôt c√°ch chi ti·∫øt v√† ch√≠nh x√°c.
    
    Khi c·∫ßn thi·∫øt, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c c√¥ng c·ª• ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ ho√†n th√†nh nhi·ªám v·ª•.
    
    Lu√¥n duy tr√¨ m·ªôt gi·ªçng ƒëi·ªáu th√¢n thi·ªán v√† chuy√™n nghi·ªáp.
    """
```

### T·∫°o agent m·ªõi ho√†n to√†n

ƒê·ªÉ t·∫°o m·ªôt agent m·ªõi t·ª´ ƒë·∫ßu:

1. T·∫°o file `my_agent.py` trong th∆∞ m·ª•c `agent_template/core/`:

```python
"""
Tri·ªÉn khai agent t√πy ch·ªânh m·ªõi.
"""

import os
from typing import Union, Dict, Any
from datetime import datetime

import logfire
from pydantic_ai import Agent, RunContext
from dotenv import load_dotenv

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()
logfire.configure(send_to_logfire='if-token-present')

# C·∫•u h√¨nh model
MODEL_NAME = "openai:gpt-4o"
TEMPERATURE = 0.7

# Kh·ªüi t·∫°o agent
custom_agent = Agent[
    CustomDeps,  # ƒê·ªãnh nghƒ©a dependencies c·ªßa b·∫°n
    Union[str, CustomResult]  # C√°c lo·∫°i k·∫øt qu·∫£ c√≥ th·ªÉ tr·∫£ v·ªÅ
](
    MODEL_NAME,
    system_prompt="Prompt h·ªá th·ªëng t√πy ch·ªânh c·ªßa b·∫°n",
    temperature=TEMPERATURE,
    retries=2,
)

# ƒêƒÉng k√Ω tools
@custom_agent.tool
async def custom_tool(
    ctx: RunContext[CustomDeps],
    param1: str
) -> CustomResult:
    """M√¥ t·∫£ c√¥ng c·ª• t√πy ch·ªânh."""
    # Tri·ªÉn khai logic
    return CustomResult(result="K·∫øt qu·∫£ c√¥ng c·ª•")

# H√†m x·ª≠ l√Ω ƒë·∫ßu v√†o
async def process_with_custom_agent(user_input: str) -> str:
    """X·ª≠ l√Ω ƒë·∫ßu v√†o v·ªõi agent t√πy ch·ªânh."""
    # Tri·ªÉn khai logic x·ª≠ l√Ω
    result = await custom_agent.run(user_input)
    return result.data
```

2. T√≠ch h·ª£p agent m·ªõi v√†o `agent_service.py`:

```python
from agent_template.core.my_agent import process_with_custom_agent

# Trong AgentService
async def process_message(self, message: str, thread_id: Optional[str] = None):
    # ...
    if self.config.use_custom_agent:
        # S·ª≠ d·ª•ng agent t√πy ch·ªânh
        response = await process_with_custom_agent(message)
    # ...
```

### T·∫°o c√¥ng c·ª• m·ªõi

1. T·∫°o m·ªôt file m·ªõi trong `agent_template/tools/`
2. ƒê·ªãnh nghƒ©a l·ªõp k·∫øt qu·∫£ s·ª≠ d·ª•ng Pydantic
3. Tri·ªÉn khai c√°c h√†m ti·ªán √≠ch
4. Trong `agent.py`, ƒëƒÉng k√Ω c√¥ng c·ª• m·ªõi v·ªõi `@agent.tool` decorator:

```python
@agent.tool
async def your_tool_name(
    ctx: RunContext[Deps],
    param1: str,
    param2: int = 0
) -> YourResultType:
    """M√¥ t·∫£ c√¥ng c·ª• c·ªßa b·∫°n."""
    # Tri·ªÉn khai logic
    result = your_utility_function(param1, param2)
    return YourResultType(result=result)
```

### T√πy ch·ªânh Workflow LangGraph

N·∫øu mu·ªën th√™m c√°c node ho·∫∑c edge m·ªõi v√†o ƒë·ªì th·ªã LangGraph:

1. M·ªü `agent_template/workflows/graph.py`
2. Th√™m c√°c node v√† edge m·ªõi:
```python
# Th√™m node m·ªõi
workflow.add_node("my_custom_node", my_custom_function)

# Th√™m edge
workflow.add_edge("process", "my_custom_node")
workflow.add_edge("my_custom_node", "continue")
```

## üöÄ H∆∞·ªõng d·∫´n x√¢y d·ª±ng Agent ho√†n ch·ªânh t·ª´ A-Z

### B∆∞·ªõc 1: Thi·∫øt l·∫≠p c∆° b·∫£n

1. Clone repo v√† c√†i ƒë·∫∑t dependencies:
   ```bash
   git clone https://github.com/yourusername/agent-template.git
   cd agent-template
   pip install -r requirements.txt
   ```

2. C·∫•u h√¨nh API keys v√† model:
   ```bash
   cp .env.example .env
   # Ch·ªânh s·ª≠a file .env v·ªõi API key v√† model c·ªßa b·∫°n
   ```

### B∆∞·ªõc 2: T√πy ch·ªânh Agent

1. **Ch·ªçn model ph√π h·ª£p**:
   - C·∫≠p nh·∫≠t `MODEL_NAME` trong `.env` ho·∫∑c `agent.py`
   - C√¢n nh·∫Øc s·ª≠ d·ª•ng nhi·ªÅu model cho c√°c t√°c v·ª• kh√°c nhau

2. **ƒêi·ªÅu ch·ªânh system prompt**:
   - S·ª≠a ƒë·ªïi h√†m `get_simple_assistant_prompt()` trong `utils/prompts.py`
   - ƒê·ªãnh h√¨nh personality v√† kh·∫£ nƒÉng c·ªßa agent

3. **T·∫°o tools c·∫ßn thi·∫øt**:
   - T·∫°o file m·ªõi trong `tools/` cho m·ªói kh·∫£ nƒÉng
   - ƒê·ªãnh nghƒ©a k·∫øt qu·∫£ tr·∫£ v·ªÅ s·ª≠ d·ª•ng Pydantic
   - ƒêƒÉng k√Ω tool v·ªõi decorator `@agent.tool`

### B∆∞·ªõc 3: Tri·ªÉn khai giao di·ªán

1. **Ch·ªçn gi·ªØa CLI v√† API ho·∫∑c c·∫£ hai**:
   - T√πy ch·ªânh c√°c l·ªánh CLI ho·∫∑c endpoint API n·∫øu c·∫ßn
   - T√≠ch h·ª£p b·ªô nh·ªõ ƒë·ªÉ l∆∞u tr·ªØ h·ªôi tho·∫°i

2. **T√≠ch h·ª£p b·ªô nh·ªõ**:
   - C·∫•u h√¨nh `memory_dir` trong `.env` ho·∫∑c `config.py`
   - T√πy ch·ªânh c√°ch l∆∞u tr·ªØ v√† kh√¥i ph·ª•c b·ªô nh·ªõ n·∫øu c·∫ßn

### B∆∞·ªõc 4: M·ªü r·ªông v√† n√¢ng cao

1. **Scale v·ªõi nhi·ªÅu model**:
   ```python
   # Trong agent.py
   advanced_agent = Agent[Deps, Union[str, Result]](
       'openai:gpt-4o',
       system_prompt="...",
       model_settings=ModelSettings(temperature=0.7)
   )
   
   light_agent = Agent[Deps, Union[str, Result]](
       'openai:gpt-4o-mini',
       system_prompt="...",
       model_settings=ModelSettings(temperature=0.8)
   )
   ```

2. **Ph√¢n ph·ªëi tool theo nhu c·∫ßu**:
   ```python
   # Tool cho t·∫•t c·∫£ agent
   @register_for_all_agents
   async def common_tool(ctx, param): ...
   
   # Tool ch·ªâ cho advanced agent
   @advanced_agent.tool
   async def complex_tool(ctx, param): ...
   ```

3. **Tri·ªÉn khai logic ch·ªçn agent**:
   ```python
   # Trong process_input
   if "ph·ª©c t·∫°p" in user_input or len(user_input) > 200:
       active_agent = advanced_agent
   else:
       active_agent = light_agent
   ```

### B∆∞·ªõc 5: Ki·ªÉm th·ª≠ v√† tri·ªÉn khai

1. **Ki·ªÉm th·ª≠**:
   - Ki·ªÉm tra c√°c tool ri√™ng l·∫ª
   - Th·ª≠ nghi·ªám c√°c lu·ªìng h·ªôi tho·∫°i ho√†n ch·ªânh

2. **Tri·ªÉn khai**:
   - CLI: Ch·∫°y `python -m agent_template.main`
   - API: Ch·∫°y `python -m agent_template.main --api`
   - Ho·∫∑c t√≠ch h·ª£p agent v√†o ·ª©ng d·ª•ng l·ªõn h∆°n

### B∆∞·ªõc 6: Gi√°m s√°t v√† c·∫£i ti·∫øn

1. **Thu th·∫≠p feedback**:
   - L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i v√† ph√¢n t√≠ch
   - S·ª≠ d·ª•ng LogFire ƒë·ªÉ gi√°m s√°t n·∫øu c·∫ßn

2. **C·∫£i ti·∫øn li√™n t·ª•c**:
   - C·∫≠p nh·∫≠t prompt h·ªá th·ªëng
   - Th√™m tool m·ªõi
   - ƒêi·ªÅu ch·ªânh c·∫•u h√¨nh model

Theo quy tr√¨nh n√†y, b·∫°n c√≥ th·ªÉ x√¢y d·ª±ng m·ªôt agent ho√†n ch·ªânh, ph√π h·ª£p v·ªõi nhu c·∫ßu c·ª• th·ªÉ v√† c√≥ kh·∫£ nƒÉng m·ªü r·ªông theo th·ªùi gian.

## üß™ Ki·ªÉm th·ª≠

```bash
# Test API
python -m pytest tests/test_api.py -v

# Test workflow
python -m pytest tests/test_workflows.py -v
```

## üìö T√†i nguy√™n

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Pydantic-AI Documentation](https://docs.pydantic-ai.dev/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
