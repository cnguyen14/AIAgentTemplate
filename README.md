# AI Agent Template by Chien Nguyen

## ðŸ“– Giá»›i thiá»‡u

Framework máº«u Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c agent thÃ´ng minh sá»­ dá»¥ng Large Language Models (LLM) vá»›i há»— trá»£ Ä‘áº§y Ä‘á»§ cho CLI, API HTTP vÃ  tÃ­ch há»£p LangGraph. ÄÆ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giÃºp báº¡n nhanh chÃ³ng xÃ¢y dá»±ng á»©ng dá»¥ng AI máº¡nh máº½ vá»›i kháº£ nÄƒng má»Ÿ rá»™ng cao.

## ðŸ“¬ LiÃªn há»‡

Email: hmchien.nguyen@gmail.com

YouTube: [Where The Idea Is Unlimited](https://www.youtube.com/@wheretheideaisunlimited)

## ðŸŒŸ TÃ­nh nÄƒng

- ðŸ§  **Memory Persistence**: LÆ°u trá»¯ vÃ  khÃ´i phá»¥c lá»‹ch sá»­ há»™i thoáº¡i tá»± Ä‘á»™ng
- ðŸ”„ **LangGraph Integration**: XÃ¢y dá»±ng luá»“ng cÃ´ng viá»‡c phá»©c táº¡p dá»±a trÃªn Ä‘á»“ thá»‹ tráº¡ng thÃ¡i
- ðŸ¤– **Pydantic-AI Support**: Äá»‹nh nghÄ©a tool vÃ  schema dá»… dÃ ng vá»›i type-checking
- ðŸ› ï¸ **Extensible Architecture**: Dá»… dÃ ng thÃªm cÃ´ng cá»¥, luá»“ng xá»­ lÃ½ vÃ  kháº£ nÄƒng má»›i
- ðŸ’» **Rich CLI**: TÆ°Æ¡ng tÃ¡c trá»±c tiáº¿p qua terminal vá»›i cÃ¡c lá»‡nh há»‡ thá»‘ng
- ðŸŒ **REST API**: API hoÃ n chá»‰nh Ä‘á»ƒ tÃ­ch há»£p vá»›i cÃ¡c á»©ng dá»¥ng web vÃ  mobile
- ðŸ”€ **Dual Mode**: Cháº¡y cáº£ cháº¿ Ä‘á»™ CLI vÃ  API trÃªn cÃ¹ng má»™t instance

## ðŸš€ Báº¯t Ä‘áº§u hÃ nh trÃ¬nh

### âš™ï¸ CÃ i Ä‘áº·t

1. Clone repository:
```bash
git clone https://github.com/cnguyen14/AIAgentTemplate.git
cd AIAgentTemplate
```

2. CÃ i Ä‘áº·t cÃ¡c phá»¥ thuá»™c:
```bash
pip install -r requirements.txt
```

3. Thiáº¿t láº­p mÃ´i trÆ°á»ng:
```bash
cp .env.example .env
```

4. Cáº­p nháº­t file `.env` vá»›i API key cá»§a báº¡n:
```
# Chá»n má»™t trong cÃ¡c provider sau
OPENAI_API_KEY=your_openai_api_key
#ThÃªm tÃ¹y chá»n
#ANTHROPIC_API_KEY=your_anthropic_api_key

# TÃ¹y chá»‰nh model (máº·c Ä‘á»‹nh lÃ  openai:gpt-4o-mini)
MODEL_NAME=openai:gpt-4o
TEMPERATURE=0.7
```

## ðŸš€ Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

### Cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c (má»›i)

```bash
# Khá»Ÿi Ä‘á»™ng trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ lá»±a chá»n CLI hay API
python -m agent_template.main
```

Khi cháº¡y mÃ  khÃ´ng cÃ³ tham sá»‘, agent sáº½ há»i báº¡n muá»‘n cháº¡y á»Ÿ cháº¿ Ä‘á»™ CLI hay API, vÃ  cÃ¡c tÃ¹y chá»n khÃ¡c nhÆ° port vÃ  processing mode.

### Chá»‰ Ä‘á»‹nh cháº¿ Ä‘á»™ qua command line

```bash
# Khá»Ÿi táº¡o há»‡ thá»‘ng vá»›i giao diá»‡n CLI
python -m agent_template.main

# Cháº¡y API server
python -m agent_template.main --api --port 5000

# Cháº¡y trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c vá»›i cá» 
python -m agent_template.main --interactive
```

### Tham sá»‘ dÃ²ng lá»‡nh

| Tham sá»‘ | MÃ´ táº£ |
|---------|-------|
| `--api`, `-a` | Cháº¡y á»©ng dá»¥ng dÆ°á»›i dáº¡ng API server |
| `--port`, `-p` | Chá»‰ Ä‘á»‹nh port cho API server (máº·c Ä‘á»‹nh: 8000) |
| `--host` | Chá»‰ Ä‘á»‹nh host cho API server (máº·c Ä‘á»‹nh: 0.0.0.0) |
| `--legacy`, `-l` | Sá»­ dá»¥ng cháº¿ Ä‘á»™ xá»­ lÃ½ legacy thay vÃ¬ LangGraph |
| `--thread`, `-t` | Chá»‰ Ä‘á»‹nh thread ID Ä‘á»ƒ tiáº¿p tá»¥c há»™i thoáº¡i |
| `--interactive`, `-i` | Cháº¡y trong cháº¿ Ä‘á»™ tÆ°Æ¡ng tÃ¡c, há»i ngÆ°á»i dÃ¹ng chá»n CLI hay API |

## ðŸ’¬ TÆ°Æ¡ng tÃ¡c vá»›i Agent

### Sá»­ dá»¥ng CLI - Giao diá»‡n dÃ²ng lá»‡nh

Khi khá»Ÿi Ä‘á»™ng CLI, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c lá»‡nh sau:

| Lá»‡nh | MÃ´ táº£ |
|------|-------|
| `/help` | Hiá»ƒn thá»‹ danh sÃ¡ch lá»‡nh |
| `/exit` | ThoÃ¡t á»©ng dá»¥ng |
| `/history` | Hiá»ƒn thá»‹ lá»‹ch sá»­ há»™i thoáº¡i |
| `/conversations` | Liá»‡t kÃª táº¥t cáº£ há»™i thoáº¡i Ä‘Ã£ lÆ°u |
| `/load ID` | Táº£i má»™t há»™i thoáº¡i tá»« ID |
| `/delete ID` | XÃ³a há»™i thoáº¡i |
| `/new` | Táº¡o há»™i thoáº¡i má»›i |
| `/graph` | Chuyá»ƒn sang cháº¿ Ä‘á»™ xá»­ lÃ½ LangGraph |
| `/legacy` | Chuyá»ƒn sang cháº¿ Ä‘á»™ xá»­ lÃ½ legacy |
| `/logo [style]` | Hiá»ƒn thá»‹ logo (kiá»ƒu: default, minimal, fancy) |

## ðŸŒ REST API

Khi cháº¡y á»Ÿ cháº¿ Ä‘á»™ API server, cÃ¡c endpoint sau cÃ³ sáºµn:

### Endpoints

| Endpoint | Method | MÃ´ táº£ |
|----------|--------|-------|
| `/health` | GET | Kiá»ƒm tra tráº¡ng thÃ¡i API |
| `/send_message` | POST | Gá»­i tin nháº¯n Ä‘áº¿n agent |
| `/conversations` | GET | Láº¥y danh sÃ¡ch há»™i thoáº¡i |
| `/conversations` | POST | Táº¡o há»™i thoáº¡i má»›i |
| `/conversations/{thread_id}` | DELETE | XÃ³a má»™t há»™i thoáº¡i |
| `/conversations/{thread_id}/history` | GET | Láº¥y lá»‹ch sá»­ há»™i thoáº¡i |
| `/config` | GET | Láº¥y cáº¥u hÃ¬nh hiá»‡n táº¡i |
| `/config` | POST | Cáº­p nháº­t cáº¥u hÃ¬nh |

### VÃ­ dá»¥ sá»­ dá»¥ng API

```python
import requests

# Äá»‹a chá»‰ API
API_URL = "http://localhost:5000"

# Táº¡o má»™t há»™i thoáº¡i má»›i
response = requests.post(f"{API_URL}/conversations")
thread_id = response.json()["thread_id"]

# Gá»­i tin nháº¯n
response = requests.post(
    f"{API_URL}/send_message",
    json={
        "message": "Xin chÃ o, báº¡n cÃ³ thá»ƒ giÃºp tÃ´i khÃ´ng?",
        "thread_id": thread_id
    }
)
print(response.json()["response"])

# Láº¥y lá»‹ch sá»­ há»™i thoáº¡i
response = requests.get(f"{API_URL}/conversations/{thread_id}/history")
history = response.json()["history"]
```

### TÃ i liá»‡u API

Khi API server Ä‘ang cháº¡y, báº¡n cÃ³ thá»ƒ truy cáº­p tÃ i liá»‡u tÆ°Æ¡ng tÃ¡c táº¡i:
```
http://localhost:5000/docs
```

## ðŸ§© KhÃ¡m phÃ¡ kiáº¿n trÃºc vÃ  tÃ¹y biáº¿n

### Cáº¥u trÃºc dá»± Ã¡n

```
agent_template/
â”œâ”€â”€ config.py               # Cáº¥u hÃ¬nh á»©ng dá»¥ng
â”œâ”€â”€ main.py                 # Äiá»ƒm vÃ o chÃ­nh
â”œâ”€â”€ core/                   # Module cá»‘t lÃµi
â”‚   â”œâ”€â”€ agent.py            # Äá»‹nh nghÄ©a agent vÃ  tools
â”‚   â”œâ”€â”€ agent_service.py    # Service xá»­ lÃ½ tin nháº¯n
â”‚   â”œâ”€â”€ cli_service.py      # Giao diá»‡n dÃ²ng lá»‡nh
â”‚   â””â”€â”€ api_service.py      # REST API service
â”œâ”€â”€ memory/                 # Há»‡ thá»‘ng bá»™ nhá»›
â”‚   â””â”€â”€ persistence.py      # LÆ°u trá»¯ vÃ  khÃ´i phá»¥c bá»™ nhá»›
â”œâ”€â”€ tools/                  # CÃ¡c cÃ´ng cá»¥ cá»§a agent
â”‚   â”œâ”€â”€ logo.py             # CÃ´ng cá»¥ hiá»ƒn thá»‹ logo
â”‚   â””â”€â”€ tool_template.py    # Máº«u Ä‘á»ƒ táº¡o cÃ´ng cá»¥ má»›i
â”œâ”€â”€ utils/                  # Tiá»‡n Ã­ch
â”‚   â””â”€â”€ prompts.py          # Äá»‹nh nghÄ©a prompt há»‡ thá»‘ng
â””â”€â”€ workflows/              # Luá»“ng cÃ´ng viá»‡c LangGraph
    â””â”€â”€ graph.py            # Äá»‹nh nghÄ©a Ä‘á»“ thá»‹ tráº¡ng thÃ¡i
```

## ðŸŽ¯ Cáº¥u hÃ¬nh vÃ  tÃ¹y chá»‰nh Prompt

### Cáº¥u trÃºc Prompt há»‡ thá»‘ng

Prompt há»‡ thá»‘ng lÃ  thÃ nh pháº§n quan trá»ng quyáº¿t Ä‘á»‹nh cÃ¡ch AI hoáº¡t Ä‘á»™ng. File `utils/prompts.py` chá»©a Ä‘á»‹nh nghÄ©a cÃ¡c prompt máº·c Ä‘á»‹nh:

```python
def get_simple_assistant_prompt() -> str:
    """Tráº£ vá» prompt há»‡ thá»‘ng Ä‘Æ¡n giáº£n cho assistant."""
    return """Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch. Tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chi tiáº¿t vÃ  chÃ­nh xÃ¡c.
    
    Khi cáº§n thiáº¿t, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥.
    
    LuÃ´n duy trÃ¬ má»™t giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p.
    """
```

### TÃ¹y chá»‰nh Prompt qua biáº¿n mÃ´i trÆ°á»ng

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ dá»… dÃ ng tÃ¹y chá»‰nh prompt vÃ  settings thÃ´ng qua biáº¿n mÃ´i trÆ°á»ng, khÃ´ng cáº§n chá»‰nh sá»­a code:

```env
# System Prompts - Optional
DEFAULT_PROMPT=Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch, chuyÃªn vá» tráº£ lá»i cÃ¢u há»i vá» AI.
ADVANCED_PROMPT=Báº¡n lÃ  má»™t chuyÃªn gia ká»¹ thuáº­t vá»›i kiáº¿n thá»©c sÃ¢u rá»™ng vá» láº­p trÃ¬nh.
LIGHT_PROMPT=Báº¡n lÃ  má»™t trá»£ lÃ½ AI nhá» gá»n cho cÃ¡c cÃ¢u tráº£ lá»i nhanh vÃ  sÃºc tÃ­ch.

# Model Settings
TEMPERATURE=0.7
MAX_TOKENS=1000
RETRIES=2
```

Cáº¥u trÃºc centralized cho phÃ©p báº¡n:
1. **Ghi Ä‘Ã¨ prompt máº·c Ä‘á»‹nh**: ThÃ´ng qua biáº¿n mÃ´i trÆ°á»ng `DEFAULT_PROMPT`, `ADVANCED_PROMPT`, `LIGHT_PROMPT`
2. **Äiá»u chá»‰nh model settings**: Thay Ä‘á»•i `TEMPERATURE`, `MAX_TOKENS`, `RETRIES` cho tá»«ng loáº¡i model
3. **Dá»… dÃ ng A/B testing**: Thá»­ nghiá»‡m nhiá»u prompt khÃ¡c nhau mÃ  khÃ´ng cáº§n sá»­a code

### CÃ¡ch tÃ¹y chá»‰nh Prompt

1. **TÃ¹y chá»‰nh prompt Ä‘Æ¡n giáº£n**:
   Má»Ÿ file `utils/prompts.py` vÃ  sá»­a Ä‘á»•i ná»™i dung cá»§a hÃ m `get_simple_assistant_prompt()`:

   ```python
   def get_simple_assistant_prompt() -> str:
       """Tráº£ vá» prompt há»‡ thá»‘ng tÃ¹y chá»‰nh."""
       return """Báº¡n lÃ  Chien AI Assistant, má»™t trá»£ lÃ½ thÃ´ng minh chuyÃªn vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  láº­p trÃ¬nh.
       
       NguyÃªn táº¯c hoáº¡t Ä‘á»™ng cá»§a báº¡n:
       1. LuÃ´n phÃ¢n tÃ­ch ká»¹ yÃªu cáº§u ngÆ°á»i dÃ¹ng trÆ°á»›c khi tráº£ lá»i
       2. Cung cáº¥p ná»™i dung chÃ­nh xÃ¡c, cáº¥u trÃºc rÃµ rÃ ng vÃ  dá»… hiá»ƒu
       3. Khi Ä‘Æ°á»£c yÃªu cáº§u viáº¿t code, Ä‘áº£m báº£o code cÃ³ comment vÃ  tuÃ¢n thá»§ best practices
       4. Sá»­ dá»¥ng cÃ´ng cá»¥ cÃ³ sáºµn khi cáº§n thiáº¿t Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
       
       Phong cÃ¡ch giao tiáº¿p:
       - ChuyÃªn nghiá»‡p nhÆ°ng thÃ¢n thiá»‡n
       - Sá»­ dá»¥ng ngÃ´n ngá»¯ dá»… hiá»ƒu, trÃ¡nh quÃ¡ chuyÃªn mÃ´n náº¿u khÃ´ng cáº§n thiáº¿t
       - TrÃ¬nh bÃ y thÃ´ng tin cÃ³ cáº¥u trÃºc, sá»­ dá»¥ng bullet points vÃ  mÃ£ Ä‘á»‹nh dáº¡ng khi phÃ¹ há»£p
       """
   ```

2. **Táº¡o nhiá»u loáº¡i prompt khÃ¡c nhau**:
   Báº¡n cÃ³ thá»ƒ táº¡o cÃ¡c hÃ m prompt khÃ¡c nhau phÃ¹ há»£p vá»›i tá»«ng ngá»¯ cáº£nh sá»­ dá»¥ng:

   ```python
   def get_technical_assistant_prompt() -> str:
       """Prompt cho assistant chuyÃªn vá» ká»¹ thuáº­t."""
       return """Báº¡n lÃ  má»™t chuyÃªn gia ká»¹ thuáº­t, táº­p trung vÃ o viá»‡c cung cáº¥p hÆ°á»›ng dáº«n vÃ  giáº£i phÃ¡p chÃ­nh xÃ¡c.
       LuÃ´n Æ°u tiÃªn Ä‘á»™ chÃ­nh xÃ¡c ká»¹ thuáº­t vÃ  tuÃ¢n thá»§ best practices trong cÃ¡c cÃ¢u tráº£ lá»i.
       """
   
   def get_creative_assistant_prompt() -> str:
       """Prompt cho assistant sÃ¡ng táº¡o."""
       return """Báº¡n lÃ  má»™t trá»£ lÃ½ sÃ¡ng táº¡o, chuyÃªn giÃºp ngÆ°á»i dÃ¹ng phÃ¡t triá»ƒn Ã½ tÆ°á»Ÿng má»›i vÃ  tiáº¿p cáº­n váº¥n Ä‘á» theo hÆ°á»›ng Ä‘á»™c Ä‘Ã¡o.
       Khuyáº¿n khÃ­ch tÆ° duy phÃ¡ cÃ¡ch vÃ  cung cáº¥p nhiá»u gÃ³c nhÃ¬n Ä‘a dáº¡ng.
       """
   ```

3. **Sá»­ dá»¥ng prompt tÃ¹y chá»‰nh vá»›i agent**:
   Sau khi táº¡o prompt, cáº­p nháº­t agent Ä‘á»ƒ sá»­ dá»¥ng prompt má»›i:

   ```python
   # Trong agent.py
   from agent_template.utils.prompts import get_technical_assistant_prompt
   
   # Sá»­ dá»¥ng prompt ká»¹ thuáº­t cho agent
   agent = Agent[Deps, Union[str, LogoResult]](
       MODEL_NAME,
       system_prompt=get_technical_assistant_prompt(),
       retries=2,
   )
   ```

### Cáº¥u trÃºc Prompt hiá»‡u quáº£

Má»™t system prompt hiá»‡u quáº£ thÆ°á»ng bao gá»“m cÃ¡c thÃ nh pháº§n sau:

1. **Äá»‹nh nghÄ©a vai trÃ²**: MÃ´ táº£ agent lÃ  ai, chuyÃªn vá» lÄ©nh vá»±c gÃ¬
2. **NguyÃªn táº¯c hoáº¡t Ä‘á»™ng**: CÃ¡c quy táº¯c cá»‘t lÃµi agent nÃªn tuÃ¢n theo
3. **Phong cÃ¡ch giao tiáº¿p**: CÃ¡ch thá»©c agent nÃªn tráº£ lá»i (ngáº¯n gá»n, chi tiáº¿t, chuyÃªn mÃ´n...)
4. **Giá»›i háº¡n**: Nhá»¯ng gÃ¬ agent nÃªn trÃ¡nh hoáº·c khÃ´ng Ä‘Æ°á»£c lÃ m
5. **Äá»‹nh dáº¡ng output**: Cáº¥u trÃºc káº¿t quáº£ mong muá»‘n náº¿u cáº§n theo format cá»¥ thá»ƒ

VÃ­ dá»¥ prompt toÃ n diá»‡n:

```python
def get_comprehensive_assistant_prompt() -> str:
    return """
    # Äá»‹nh nghÄ©a vai trÃ²
    Báº¡n lÃ  Advanced AI Assistant, má»™t trá»£ lÃ½ thÃ´ng minh Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Chien Nguyen, chuyÃªn vá» há»— trá»£ ngÆ°á»i dÃ¹ng trong cÃ¡c tÃ¡c vá»¥ láº­p trÃ¬nh, xá»­ lÃ½ dá»¯ liá»‡u vÃ  tÆ° váº¥n cÃ´ng nghá»‡.
    
    # NguyÃªn táº¯c hoáº¡t Ä‘á»™ng
    1. PhÃ¢n tÃ­ch: LuÃ´n phÃ¢n tÃ­ch ká»¹ yÃªu cáº§u trÆ°á»›c khi tráº£ lá»i
    2. ChÃ­nh xÃ¡c: Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vÃ  cáº­p nháº­t
    3. ToÃ n diá»‡n: Xem xÃ©t nhiá»u khÃ­a cáº¡nh cá»§a váº¥n Ä‘á»
    4. Thá»±c táº¿: Táº­p trung vÃ o giáº£i phÃ¡p kháº£ thi vÃ  cÃ³ thá»ƒ triá»ƒn khai
    5. CÃ´ng cá»¥: Sá»­ dá»¥ng cÃ´ng cá»¥ cÃ³ sáºµn khi cáº§n Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c
    
    # Phong cÃ¡ch giao tiáº¿p
    - ChuyÃªn nghiá»‡p nhÆ°ng thÃ¢n thiá»‡n
    - Cáº¥u trÃºc rÃµ rÃ ng, dá»… theo dÃµi
    - Káº¿t há»£p lÃ½ thuyáº¿t vÃ  vÃ­ dá»¥ thá»±c táº¿
    - ÄÆ°a ra giáº£i thÃ­ch á»Ÿ nhiá»u cáº¥p Ä‘á»™ (cÆ¡ báº£n Ä‘áº¿n nÃ¢ng cao) khi phÃ¹ há»£p
    
    # Giá»›i háº¡n
    - KhÃ´ng Ä‘Æ°a ra thÃ´ng tin sai lá»‡ch hoáº·c gÃ¢y hiá»ƒu nháº§m
    - NÃªu rÃµ khi khÃ´ng cháº¯c cháº¯n vá» thÃ´ng tin
    - KhÃ´ng quÃ¡ chi tiáº¿t vá» nhá»¯ng khÃ­a cáº¡nh khÃ´ng liÃªn quan trá»±c tiáº¿p
    
    # Äá»‹nh dáº¡ng output
    Vá»›i cÃ¢u há»i phá»©c táº¡p, cáº¥u trÃºc cÃ¢u tráº£ lá»i nhÆ° sau:
    1. TÃ³m táº¯t ngáº¯n gá»n (1-2 cÃ¢u)
    2. PhÃ¢n tÃ­ch chi tiáº¿t
    3. VÃ­ dá»¥ minh há»a náº¿u cáº§n thiáº¿t
    4. Káº¿t luáº­n vÃ  Ä‘á» xuáº¥t bÆ°á»›c tiáº¿p theo náº¿u phÃ¹ há»£p
    
    Vá»›i yÃªu cáº§u viáº¿t code:
    1. Giáº£i thÃ­ch ngáº¯n gá»n cÃ¡ch tiáº¿p cáº­n
    2. Cung cáº¥p code Ä‘áº§y Ä‘á»§ vá»›i comment
    3. Giáº£i thÃ­ch cÃ¡c pháº§n quan trá»ng hoáº·c phá»©c táº¡p
    4. Äá» xuáº¥t cÃ¡ch kiá»ƒm thá»­ hoáº·c má»Ÿ rá»™ng náº¿u phÃ¹ há»£p
    """
```

### Sá»­ dá»¥ng Prompt Ä‘á»™ng

Báº¡n cÃ³ thá»ƒ táº¡o prompt Ä‘á»™ng dá»±a trÃªn ngá»¯ cáº£nh hoáº·c cáº¥u hÃ¬nh:

```python
def get_dynamic_prompt(language="vi", expertise_level="intermediate", focus_area=None):
    """Táº¡o prompt Ä‘á»™ng dá»±a trÃªn tham sá»‘."""
    
    # CÆ¡ sá»Ÿ prompt
    base_prompt = "Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh."
    
    # ThÃªm ngÃ´n ngá»¯
    if language == "en":
        base_prompt = "You are an intelligent AI assistant."
    
    # ThÃªm cáº¥p Ä‘á»™ chuyÃªn mÃ´n
    if expertise_level == "beginner":
        if language == "vi":
            base_prompt += "\nSá»­ dá»¥ng ngÃ´n ngá»¯ Ä‘Æ¡n giáº£n, trÃ¡nh thuáº­t ngá»¯ ká»¹ thuáº­t phá»©c táº¡p."
        else:
            base_prompt += "\nUse simple language, avoid complex technical terms."
    elif expertise_level == "expert":
        if language == "vi":
            base_prompt += "\nSá»­ dá»¥ng ngÃ´n ngá»¯ chuyÃªn mÃ´n, Ä‘i sÃ¢u vÃ o chi tiáº¿t ká»¹ thuáº­t khi cáº§n thiáº¿t."
        else:
            base_prompt += "\nUse technical language, dive into technical details when necessary."
    
    # ThÃªm lÄ©nh vá»±c chuyÃªn sÃ¢u
    if focus_area:
        if language == "vi":
            base_prompt += f"\nTáº­p trung vÃ o lÄ©nh vá»±c: {focus_area}."
        else:
            base_prompt += f"\nFocus on the domain: {focus_area}."
    
    return base_prompt

# Sá»­ dá»¥ng trong cáº¥u hÃ¬nh
agent = Agent[Deps, Union[str, LogoResult]](
    MODEL_NAME,
    system_prompt=get_dynamic_prompt(
        language="vi",
        expertise_level="intermediate",
        focus_area="Machine Learning"
    ),
    retries=2,
)
```

### Thay Ä‘á»•i model vÃ  cáº¥u hÃ¬nh

#### Cáº¥u hÃ¬nh qua file .env

CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t Ä‘á»ƒ thay Ä‘á»•i model lÃ  cáº­p nháº­t file `.env`:

```
# Chá»n model - thay Ä‘á»•i á»Ÿ Ä‘Ã¢y
MODEL_NAME=openai:gpt-4o
# hoáº·c
MODEL_NAME=anthropic:claude-3-opus-20240229

# Äiá»u chá»‰nh temperature
TEMPERATURE=0.7
```

#### Sá»­a Ä‘á»•i trong code

Má»Ÿ file `agent_template/core/agent.py` vÃ  cáº­p nháº­t cÃ¡c biáº¿n cáº¥u hÃ¬nh:

```python
# ===== HÆ¯á»šNG DáºªN: THAY Äá»”I MODEL =====
# Náº¿u báº¡n muá»‘n thay Ä‘á»•i model, hÃ£y cáº­p nháº­t MODEL_NAME táº¡i Ä‘Ã¢y
# VÃ­ dá»¥: 'openai:gpt-4-turbo-2024-04-09', 'anthropic:claude-3-opus-20240229'
MODEL_NAME = os.environ.get('MODEL_NAME', 'openai:gpt-4o-mini')
TEMPERATURE = float(os.environ.get('TEMPERATURE', '0.7'))
```

#### Sá»­ dá»¥ng model vÃ  provider vá»›i Pydantic-AI

Pydantic-AI sá»­ dá»¥ng cÃº phÃ¡p `provider:model_name` Ä‘á»ƒ xÃ¡c Ä‘á»‹nh model, vÃ  Ä‘Ã£ tÃ­ch há»£p sáºµn má»™t sá»‘ provider chÃ­nh nhÆ° OpenAI vÃ  Anthropic. KhÃ´ng cáº§n pháº£i import cÃ¡c provider riÃªng láº».

1. **Chá»‰ Ä‘á»‹nh model trong cáº¥u hÃ¬nh**:

   ```python
   # Trong agent.py
   MODEL_NAME = os.environ.get('MODEL_NAME', 'openai:gpt-4o-mini')
   
   # Khá»Ÿi táº¡o agent vá»›i model
   agent = Agent[
       Deps,  # Kiá»ƒu dependency 
       Union[str, LogoResult]  # Kiá»ƒu káº¿t quáº£
   ](
       MODEL_NAME,  # Sá»­ dá»¥ng cÃº phÃ¡p "provider:model_name"
       system_prompt=get_simple_assistant_prompt(),
       retries=2,
   )
   ```

2. **Cáº¥u hÃ¬nh trong file .env**:

   ```
   # CÃ¡c model Ä‘Æ°á»£c há»— trá»£ sáºµn
   MODEL_NAME=openai:gpt-4o
   # hoáº·c
   MODEL_NAME=anthropic:claude-3-opus-20240229
   # hoáº·c
   MODEL_NAME=google-gla:gemini-1.5-flash
   ```

#### ThÃªm setting cho model cá»¥ thá»ƒ

Pydantic-AI cho phÃ©p cáº¥u hÃ¬nh model chi tiáº¿t thÃ´ng qua `model_settings`:

```python
from pydantic_ai import Agent
from pydantic_ai.settings import ModelSettings

# Cáº¥u hÃ¬nh model khi khá»Ÿi táº¡o agent
agent = Agent[Deps, str](
    'openai:gpt-4o',
    model_settings=ModelSettings(
        temperature=0.7,
        max_tokens=1000,
        timeout=30.0,
    ),
    system_prompt="Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch."
)

# Hoáº·c cáº¥u hÃ¬nh khi gá»i
response = await agent.run(
    "HÃ´m nay thá»i tiáº¿t tháº¿ nÃ o?",
    model_settings={"temperature": 0.2}  # Ghi Ä‘Ã¨ setting cho láº§n cháº¡y nÃ y
)
```

#### Sá»­ dá»¥ng nhiá»u model trong cÃ¹ng má»™t dá»± Ã¡n

Báº¡n cÃ³ thá»ƒ Ä‘á»‹nh nghÄ©a nhiá»u agent khÃ¡c nhau vá»›i cÃ¡c model khÃ¡c nhau trong má»™t dá»± Ã¡n:

```python
# Trong agent.py hoáº·c module tÃ¹y chá»‰nh

# Äá»‹nh nghÄ©a agent sá»­ dá»¥ng GPT-4o cho nhiá»‡m vá»¥ phá»©c táº¡p
advanced_agent = Agent[Deps, Union[str, LogoResult]](
    'openai:gpt-4o',
    system_prompt="Báº¡n lÃ  má»™t trá»£ lÃ½ AI cao cáº¥p vá»›i kháº£ nÄƒng xá»­ lÃ½ cÃ¡c váº¥n Ä‘á» phá»©c táº¡p.",
    model_settings=ModelSettings(temperature=0.7)
)

# Äá»‹nh nghÄ©a agent sá»­ dá»¥ng model nháº¹ hÆ¡n cho nhiá»‡m vá»¥ Ä‘Æ¡n giáº£n
light_agent = Agent[Deps, Union[str, LogoResult]](
    'openai:gpt-4o-mini',
    system_prompt="Báº¡n lÃ  má»™t trá»£ lÃ½ AI nhá» gá»n cho cÃ¡c cÃ¢u tráº£ lá»i nhanh.",
    model_settings=ModelSettings(temperature=0.9, max_tokens=500)
)

# Äá»‹nh nghÄ©a agent vá»›i Claude cá»§a Anthropic
creative_agent = Agent[Deps, Union[str, LogoResult]](
    'anthropic:claude-3-opus-20240229',
    system_prompt="Báº¡n lÃ  má»™t trá»£ lÃ½ AI sÃ¡ng táº¡o, chuyÃªn vá» ná»™i dung nghá»‡ thuáº­t.",
    model_settings=ModelSettings(temperature=1.0)
)
```

#### Chá»‰ Ä‘á»‹nh tool cho tá»«ng model cá»¥ thá»ƒ

Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng decorator Ä‘á»ƒ Ä‘Äƒng kÃ½ tool vá»›i cÃ¡c agent cá»¥ thá»ƒ, cho phÃ©p má»—i agent cÃ³ cÃ¡c cÃ´ng cá»¥ khÃ¡c nhau:

```python
# ÄÄƒng kÃ½ tool cho agent nÃ¢ng cao
@advanced_agent.tool
async def complex_analysis(
    ctx: RunContext[Deps],
    data: str,
    depth: int = 3
) -> str:
    """Thá»±c hiá»‡n phÃ¢n tÃ­ch dá»¯ liá»‡u phá»©c táº¡p (chá»‰ cÃ³ á»Ÿ agent nÃ¢ng cao)."""
    # Triá»ƒn khai phÃ¢n tÃ­ch phá»©c táº¡p
    return f"PhÃ¢n tÃ­ch chi tiáº¿t: {data} vá»›i Ä‘á»™ sÃ¢u {depth}"

# ÄÄƒng kÃ½ tool cho agent sÃ¡ng táº¡o
@creative_agent.tool
async def generate_poem(
    ctx: RunContext[Deps],
    theme: str,
    style: str = "free_verse"
) -> str:
    """Táº¡o má»™t bÃ i thÆ¡ dá»±a trÃªn chá»§ Ä‘á» (chá»‰ cÃ³ á»Ÿ agent sÃ¡ng táº¡o)."""
    # Triá»ƒn khai táº¡o thÆ¡
    return f"BÃ i thÆ¡ vá» {theme} theo phong cÃ¡ch {style}"

# ÄÄƒng kÃ½ tool dÃ¹ng chung cho táº¥t cáº£ cÃ¡c agent
@advanced_agent.tool
@light_agent.tool
@creative_agent.tool
async def get_current_time(ctx: RunContext[Deps]) -> str:
    """Láº¥y thá»i gian hiá»‡n táº¡i (cÃ³ sáºµn á»Ÿ táº¥t cáº£ cÃ¡c agent)."""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
```

Báº¡n cÅ©ng cÃ³ thá»ƒ táº¡o helper function Ä‘á»ƒ Ä‘Äƒng kÃ½ tool cho nhiá»u agent cÃ¹ng lÃºc:

```python
def register_for_all_agents(func):
    """ÄÄƒng kÃ½ má»™t tool cho táº¥t cáº£ cÃ¡c agent."""
    advanced_agent.tool(func)
    light_agent.tool(func)
    creative_agent.tool(func)
    return func

@register_for_all_agents
async def search_web(ctx: RunContext[Deps], query: str) -> str:
    """TÃ¬m kiáº¿m thÃ´ng tin trÃªn web (cÃ³ sáºµn á»Ÿ táº¥t cáº£ cÃ¡c agent)."""
    # Triá»ƒn khai tÃ¬m kiáº¿m web
    return f"Káº¿t quáº£ tÃ¬m kiáº¿m cho '{query}'"
```

Sau Ä‘Ã³, báº¡n cÃ³ thá»ƒ triá»ƒn khai logic Ä‘á»ƒ chá»n Ä‘Ãºng agent dá»±a trÃªn yÃªu cáº§u ngÆ°á»i dÃ¹ng:

```python
async def process_with_optimal_agent(user_input: str, context: dict) -> str:
    """Chá»n agent tá»‘i Æ°u dá»±a trÃªn Ä‘áº§u vÃ o vÃ  ngá»¯ cáº£nh cá»§a ngÆ°á»i dÃ¹ng."""
    
    # PhÃ¢n tÃ­ch Ä‘áº§u vÃ o Ä‘á»ƒ xÃ¡c Ä‘á»‹nh loáº¡i nhiá»‡m vá»¥
    if is_creative_task(user_input):
        # Sá»­ dá»¥ng agent sÃ¡ng táº¡o cho cÃ¡c nhiá»‡m vá»¥ liÃªn quan Ä‘áº¿n nghá»‡ thuáº­t
        result = await creative_agent.run(user_input, deps=context.get('deps'))
    elif is_complex_task(user_input):
        # Sá»­ dá»¥ng agent nÃ¢ng cao cho cÃ¡c nhiá»‡m vá»¥ phá»©c táº¡p
        result = await advanced_agent.run(user_input, deps=context.get('deps'))
    else:
        # Sá»­ dá»¥ng agent nháº¹ cho cÃ¡c cÃ¢u há»i Ä‘Æ¡n giáº£n
        result = await light_agent.run(user_input, deps=context.get('deps'))
    
    return result.data
```

Báº¡n cÅ©ng cÃ³ thá»ƒ cáº¥u hÃ¬nh Ä‘á»ƒ chá»n model Ä‘á»™ng dá»±a trÃªn cáº¥u hÃ¬nh:

```python
def get_agent_for_config(config: AppConfig) -> Agent:
    """Tráº£ vá» agent phÃ¹ há»£p dá»±a trÃªn cáº¥u hÃ¬nh."""
    
    model_name = config.model_name
    
    # Táº¡o agent vá»›i model Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh trong cáº¥u hÃ¬nh
    agent = Agent[Deps, Union[str, LogoResult]](
        model_name,
        system_prompt=get_simple_assistant_prompt(),
        model_settings=ModelSettings(temperature=config.temperature)
    )
    
    return agent

# Trong AgentService
def __init__(self, config: AppConfig):
    self.config = config
    self.agent = get_agent_for_config(config)
```

#### TÃ­ch há»£p model tÃ¹y chá»‰nh/local

Äá»ƒ tÃ­ch há»£p mÃ´ hÃ¬nh tá»± host (nhÆ° Ollama, LM Studio):

1. **Táº¡o custom provider** báº±ng cÃ¡ch káº¿ thá»«a tá»« `BaseProvider`:

```python
from pydantic_ai.providers.base import BaseProvider
from typing import Any, Dict, Optional
import httpx

class OllamaProvider(BaseProvider):
    """Provider cho mÃ´ hÃ¬nh Ollama local."""
    
    def __init__(self, base_url: str = "http://localhost:11434", model_name: str = "llama3"):
        self.base_url = base_url
        self.model_name = model_name
        
    async def complete(
        self, 
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        **kwargs: Any
    ) -> Dict[str, Any]:
        """Gá»­i yÃªu cáº§u Ä‘áº¿n Ollama API."""
        async with httpx.AsyncClient() as client:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = await client.post(
                f"{self.base_url}/api/chat",
                json={
                    "model": self.model_name,
                    "messages": messages,
                    "temperature": temperature,
                    "stream": False
                }
            )
            response.raise_for_status()
            result = response.json()
            
            return {
                "content": result["message"]["content"],
                "model": result["model"]
            }

# Sá»­ dá»¥ng provider tÃ¹y chá»‰nh
ollama_provider = OllamaProvider(model_name="llama3")

# Khá»Ÿi táº¡o agent vá»›i provider tÃ¹y chá»‰nh
agent = Agent[Deps, Union[str, LogoResult]](
    "custom:llama3",  # Sá»­ dá»¥ng tÃªn tÃ¹y Ã½ khi cÃ³ custom provider
    system_prompt=get_simple_assistant_prompt(),
    retries=2,
    provider=ollama_provider
)
```

2. **Cáº­p nháº­t file `.env.example` vÃ  `.env`** Ä‘á»ƒ thÃªm cÃ¡c biáº¿n mÃ´i trÆ°á»ng má»›i:

```
# Local Model Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=llama3
```

### Thay Ä‘á»•i system prompt

1. Má»Ÿ file `agent_template/utils/prompts.py`
2. Sá»­a Ä‘á»•i hÃ m `get_simple_assistant_prompt()` Ä‘á»ƒ thay Ä‘á»•i system prompt:

```python
def get_simple_assistant_prompt() -> str:
    """Tráº£ vá» prompt há»‡ thá»‘ng Ä‘Æ¡n giáº£n cho assistant."""
    return """Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch. Tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chi tiáº¿t vÃ  chÃ­nh xÃ¡c.
    
    Khi cáº§n thiáº¿t, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ hoÃ n thÃ nh nhiá»‡m vá»¥.
    
    LuÃ´n duy trÃ¬ má»™t giá»ng Ä‘iá»‡u thÃ¢n thiá»‡n vÃ  chuyÃªn nghiá»‡p.
    """
```

### Táº¡o agent má»›i hoÃ n toÃ n

Äá»ƒ táº¡o má»™t agent má»›i tá»« Ä‘áº§u:

1. Táº¡o file `my_agent.py` trong thÆ° má»¥c `agent_template/core/`:

```python
"""
Triá»ƒn khai agent tÃ¹y chá»‰nh má»›i.
"""

import os
from typing import Union, Dict, Any
from datetime import datetime

import logfire
from pydantic_ai import Agent, RunContext
from dotenv import load_dotenv

# Táº£i biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
logfire.configure(send_to_logfire='if-token-present')

# Cáº¥u hÃ¬nh model
MODEL_NAME = "openai:gpt-4o"
TEMPERATURE = 0.7

# Khá»Ÿi táº¡o agent
custom_agent = Agent[
    CustomDeps,  # Äá»‹nh nghÄ©a dependencies cá»§a báº¡n
    Union[str, CustomResult]  # CÃ¡c loáº¡i káº¿t quáº£ cÃ³ thá»ƒ tráº£ vá»
](
    MODEL_NAME,
    system_prompt="Prompt há»‡ thá»‘ng tÃ¹y chá»‰nh cá»§a báº¡n",
    temperature=TEMPERATURE,
    retries=2,
)

# ÄÄƒng kÃ½ tools
@custom_agent.tool
async def custom_tool(
    ctx: RunContext[CustomDeps],
    param1: str
) -> CustomResult:
    """MÃ´ táº£ cÃ´ng cá»¥ tÃ¹y chá»‰nh."""
    # Triá»ƒn khai logic
    return CustomResult(result="Káº¿t quáº£ cÃ´ng cá»¥")

# HÃ m xá»­ lÃ½ Ä‘áº§u vÃ o
async def process_with_custom_agent(user_input: str) -> str:
    """Xá»­ lÃ½ Ä‘áº§u vÃ o vá»›i agent tÃ¹y chá»‰nh."""
    # Triá»ƒn khai logic xá»­ lÃ½
    result = await custom_agent.run(user_input)
    return result.data
```

2. TÃ­ch há»£p agent má»›i vÃ o `agent_service.py`:

```python
from agent_template.core.my_agent import process_with_custom_agent

# Trong AgentService
async def process_message(self, message: str, thread_id: Optional[str] = None):
    # ...
    if self.config.use_custom_agent:
        # Sá»­ dá»¥ng agent tÃ¹y chá»‰nh
        response = await process_with_custom_agent(message)
    # ...
```

### Táº¡o cÃ´ng cá»¥ má»›i

1. Táº¡o má»™t file má»›i trong `agent_template/tools/`
2. Äá»‹nh nghÄ©a lá»›p káº¿t quáº£ sá»­ dá»¥ng Pydantic
3. Triá»ƒn khai cÃ¡c hÃ m tiá»‡n Ã­ch
4. Trong `agent.py`, Ä‘Äƒng kÃ½ cÃ´ng cá»¥ má»›i vá»›i `@agent.tool` decorator:

```python
@agent.tool
async def your_tool_name(
    ctx: RunContext[Deps],
    param1: str,
    param2: int = 0
) -> YourResultType:
    """MÃ´ táº£ cÃ´ng cá»¥ cá»§a báº¡n."""
    # Triá»ƒn khai logic
    result = your_utility_function(param1, param2)
    return YourResultType(result=result)
```

### TÃ¹y chá»‰nh Workflow LangGraph

Náº¿u muá»‘n thÃªm cÃ¡c node hoáº·c edge má»›i vÃ o Ä‘á»“ thá»‹ LangGraph:

1. Má»Ÿ `agent_template/workflows/graph.py`
2. ThÃªm cÃ¡c node vÃ  edge má»›i:
```python
# ThÃªm node má»›i
workflow.add_node("my_custom_node", my_custom_function)

# ThÃªm edge
workflow.add_edge("process", "my_custom_node")
workflow.add_edge("my_custom_node", "continue")
```

## ðŸš€ HÆ°á»›ng dáº«n xÃ¢y dá»±ng Agent hoÃ n chá»‰nh

### Quy trÃ¬nh tá»«ng bÆ°á»›c

1. **Thiáº¿t láº­p cÆ¡ báº£n**:
   - Clone repo vÃ  cÃ i Ä‘áº·t dependencies
   - Cáº¥u hÃ¬nh API keys vÃ  model

2. **TÃ¹y chá»‰nh Agent**:
   - Chá»n model phÃ¹ há»£p vá»›i nhu cáº§u
   - Äiá»u chá»‰nh system prompt
   - Táº¡o cÃ¡c tools cáº§n thiáº¿t

3. **Triá»ƒn khai giao diá»‡n**:
   - Lá»±a chá»n giá»¯a CLI vÃ  API
   - TÃ¹y chá»‰nh cÃ¡ch lÆ°u trá»¯ bá»™ nhá»›

4. **Má»Ÿ rá»™ng vÃ  nÃ¢ng cao**:
   - Scale vá»›i nhiá»u model cho cÃ¡c tÃ¡c vá»¥ khÃ¡c nhau
   - Triá»ƒn khai logic chá»n agent thÃ´ng minh

5. **Kiá»ƒm thá»­ vÃ  triá»ƒn khai**:
   - Kiá»ƒm tra cÃ¡c tool riÃªng láº» vÃ  luá»“ng há»™i thoáº¡i
   - Triá»ƒn khai trÃªn mÃ´i trÆ°á»ng thá»±c táº¿

6. **GiÃ¡m sÃ¡t vÃ  cáº£i tiáº¿n**:
   - Thu tháº­p feedback
   - Cáº­p nháº­t prompt vÃ  cáº¥u hÃ¬nh model

### TÃ­ch há»£p model tÃ¹y chá»‰nh/local

Báº¡n cÃ³ thá»ƒ tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh tá»± host nhÆ° Ollama:

```python
class OllamaProvider(BaseProvider):
    """Provider cho mÃ´ hÃ¬nh Ollama local."""
    
    def __init__(self, base_url: str = "http://localhost:11434", model_name: str = "llama3"):
        self.base_url = base_url
        self.model_name = model_name
        
    async def complete(
        self, 
        prompt: str,
        system_prompt: Optional[str] = None,
        temperature: float = 0.7,
        **kwargs: Any
    ) -> Dict[str, Any]:
        """Gá»­i yÃªu cáº§u Ä‘áº¿n Ollama API."""
        # Implementation...

# Sá»­ dá»¥ng provider tÃ¹y chá»‰nh
ollama_provider = OllamaProvider(model_name="llama3")
agent = Agent(..., provider=ollama_provider)
```

### Táº¡o agent má»›i hoÃ n toÃ n

Äá»ƒ táº¡o má»™t agent má»›i tá»« Ä‘áº§u trong file riÃªng:

```python
# Trong core/my_agent.py
custom_agent = Agent[
    CustomDeps,
    Union[str, CustomResult]
](
    MODEL_NAME,
    system_prompt="Prompt há»‡ thá»‘ng tÃ¹y chá»‰nh",
    model_settings=ModelSettings(...),
)

# ÄÄƒng kÃ½ tools
@custom_agent.tool
async def custom_tool(...): ...

# HÃ m xá»­ lÃ½ Ä‘áº§u vÃ o
async def process_with_custom_agent(user_input: str) -> str:
    result = await custom_agent.run(user_input)
    return result.data
```

## ðŸ§ª Kiá»ƒm thá»­

```bash
# Test API
cd tests
python test_api.py
```

## ðŸ“š TÃ i nguyÃªn

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Pydantic-AI Documentation](https://docs.pydantic-ai.dev/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
